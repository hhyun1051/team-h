# base_manager.py
"""
Base Manager Agent - ê³µí†µ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤

ëª¨ë“  ë§¤ë‹ˆì € ì—ì´ì „íŠ¸(ManagerS, ManagerM, ManagerI)ê°€ ìƒì†í•˜ëŠ” ë² ì´ìŠ¤ í´ë˜ìŠ¤ì…ë‹ˆë‹¤:
- ê³µí†µ ì´ˆê¸°í™” ë¡œì§
- ì—ì´ì „íŠ¸ ìƒì„± íŒ¨í„´
- invoke/stream/get_state ë©”ì„œë“œ
- í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê´€ë¦¬
- hook ë©”ì„œë“œë¥¼ í†µí•œ í™•ì¥ ì§€ì›

"""

from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any
from pathlib import Path
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model


class ManagerBase(ABC):
    """ëª¨ë“  ë§¤ë‹ˆì € ì—ì´ì „íŠ¸ì˜ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    # í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    PROMPTS_DIR = Path(__file__).parent / "prompts"

    def __init__(
        self,
        model_name: str = "gpt-4o-mini",
        temperature: float = 0.7,
        additional_tools: Optional[List] = None,
        middleware: Optional[List] = None,
        **kwargs,
    ):
        """
        ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”

        Args:
            model_name: ì‚¬ìš©í•  LLM ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: gpt-4o-mini)
            temperature: ëª¨ë¸ temperature ì„¤ì •
            additional_tools: í•¸ë“œì˜¤í”„ ë“± ì¶”ê°€ íˆ´ ë¦¬ìŠ¤íŠ¸
            middleware: ì—ì´ì „íŠ¸ ë¯¸ë“¤ì›¨ì–´ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: HumanInTheLoopMiddleware)
            **kwargs: ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ íŒŒë¼ë¯¸í„°
        """
        manager_type = self.__class__.__name__
        print(f"[ğŸ¤–] Initializing {manager_type} Agent...")

        self.model_name = model_name
        self.temperature = temperature

        # ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ hook
        # ì´ ë©”ì„œë“œëŠ” _create_tools() í˜¸ì¶œ ì „ì— ì‹¤í–‰ë˜ì–´ì•¼ í•¨
        # (íˆ´ ìƒì„± ì‹œ ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ ì†ì„±ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
        self._pre_init_hook(**kwargs)

        # ê° ë§¤ë‹ˆì €ê°€ ìì‹ ì˜ íˆ´ì„ ìƒì„±
        self.tools = self._create_tools()
        if additional_tools:
            self.tools.extend(additional_tools)
            print(f"[â•] Added {len(additional_tools)} additional tools (handoff tools)")

        # LLM ëª¨ë¸ ìƒì„±
        model = init_chat_model(
            model=self.model_name,
            model_provider="openai",
            temperature=self.temperature,
        )

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        base_prompt = self._get_base_prompt()

        # í•¸ë“œì˜¤í”„ íˆ´ì´ ìˆìœ¼ë©´ í˜‘ì—… í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if additional_tools:
            handoff_prompt = self._get_handoff_prompt()
            system_prompt = base_prompt + handoff_prompt
        else:
            system_prompt = base_prompt

        # ê³µí†µ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ê°€
        system_prompt += self._get_closing_prompt()

        # ì—ì´ì „íŠ¸ ìƒì„± (LangChain v1)
        # Note: checkpointerëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        # TeamHGraphê°€ ìƒìœ„ ë ˆë²¨ì—ì„œ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê³ ,
        # ê° ManagerëŠ” state["messages"]ë¥¼ í†µí•´ ëŒ€í™” ë§¥ë½ì„ ë°›ìŒ
        agent_kwargs = {
            "model": model,
            "tools": self.tools,
            "system_prompt": system_prompt,
        }

        # ë¯¸ë“¤ì›¨ì–´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if middleware:
            agent_kwargs["middleware"] = middleware

        self.agent = create_agent(**agent_kwargs)

        # ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€
        self._print_initialization_summary()

    def _pre_init_hook(self, **kwargs):
        """
        ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ hook

        _create_tools() í˜¸ì¶œ ì „ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ íŠ¹ìˆ˜ ì†ì„±ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”.

        Args:
            **kwargs: ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ íŒŒë¼ë¯¸í„°

        Example:
            class ManagerM(ManagerBase):
                def _pre_init_hook(self, **kwargs):
                    self.memory = ManagerMMemory(
                        embedder_url=kwargs.get("embedder_url"),
                        ...
                    )
        """
        pass

    def _prepare_message(self, message: str, **kwargs) -> str:
        """
        ë©”ì‹œì§€ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ hook

        invoke/stream í˜¸ì¶œ ì‹œ ë©”ì‹œì§€ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ ë©”ì‹œì§€ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.

        Args:
            message: ì›ë³¸ ë©”ì‹œì§€
            **kwargs: invoke/streamì—ì„œ ì „ë‹¬ëœ ì¶”ê°€ íŒŒë¼ë¯¸í„°

        Returns:
            ì „ì²˜ë¦¬ëœ ë©”ì‹œì§€

        Example:
            class ManagerM(ManagerBase):
                def _prepare_message(self, message, **kwargs):
                    user_id = kwargs.get("user_id", "default_user")
                    return f"[User ID: {user_id}]\\n{message}"
        """
        return message

    @abstractmethod
    def _create_tools(self) -> List:
        """
        ê° ë§¤ë‹ˆì €ê°€ ìì‹ ì˜ íˆ´ì„ ì •ì˜

        Returns:
            íˆ´ í•¨ìˆ˜ ë¦¬ìŠ¤íŠ¸
        """
        pass

    def _get_prompt_filename(self) -> str:
        """
        í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª… ë°˜í™˜ (ê¸°ë³¸ê°’: í´ë˜ìŠ¤ ì´ë¦„ì„ snake_caseë¡œ ë³€í™˜)

        Returns:
            í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª… (ì˜ˆ: "manager_s.yaml")

        Note:
            ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ ë‹¤ë¥¸ íŒŒì¼ëª… ì‚¬ìš© ê°€ëŠ¥
        """
        # ManagerS -> manager_s
        class_name = self.__class__.__name__
        # CamelCaseë¥¼ snake_caseë¡œ ë³€í™˜
        import re
        snake_case = re.sub(r'(?<!^)(?=[A-Z])', '_', class_name).lower()
        return f"{snake_case}.yaml"

    def _load_prompt_from_file(self, filename: str) -> str:
        """
        í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ (YAML í˜•ì‹)

        Args:
            filename: í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª… (prompts/ ë””ë ‰í† ë¦¬ ë‚´)

        Returns:
            í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´

        Raises:
            FileNotFoundError: í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ì„ ê²½ìš°
        """
        prompt_path = self.PROMPTS_DIR / filename

        if not prompt_path.exists():
            raise FileNotFoundError(
                f"Prompt file not found: {prompt_path}\n"
                f"Please create the prompt file at: {prompt_path}"
            )

        # YAML íŒŒì¼ ì½ê¸°
        try:
            import yaml
            with open(prompt_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)

            # 'content' í‚¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
            if isinstance(data, dict) and 'content' in data:
                return data['content'].strip()
            else:
                raise ValueError(f"YAML file must contain 'content' key: {prompt_path}")
        except Exception as e:
            raise ValueError(f"Failed to load YAML prompt from {prompt_path}: {e}")

    def _get_base_prompt(self) -> str:
        """
        ë² ì´ìŠ¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜

        ê¸°ë³¸ì ìœ¼ë¡œ prompts/ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ ì§ì ‘ ë¬¸ìì—´ ë°˜í™˜ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.

        Returns:
            ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        filename = self._get_prompt_filename()
        return self._load_prompt_from_file(filename)

    def _get_handoff_prompt(self) -> str:
        """
        í•¸ë“œì˜¤í”„ íˆ´ì´ ìˆì„ ë•Œ ì¶”ê°€ë˜ëŠ” í˜‘ì—… í”„ë¡¬í”„íŠ¸

        ê¸°ë³¸ì ìœ¼ë¡œ prompts/handoff_common.yamlì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.

        Returns:
            í•¸ë“œì˜¤í”„ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        return self._load_prompt_from_file("handoff_common.yaml")

    def _get_closing_prompt(self) -> str:
        """
        ëª¨ë“  í”„ë¡¬í”„íŠ¸ ë§ˆì§€ë§‰ì— ì¶”ê°€ë˜ëŠ” ê³µí†µ ë©”ì‹œì§€

        Returns:
            ë§ˆì§€ë§‰ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        return "\n\nBe helpful, accurate, and respond in Korean when appropriate."

    def _print_initialization_summary(self):
        """ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥"""
        manager_type = self.__class__.__name__
        print(f"[âœ…] {manager_type} Agent initialized successfully")
        print(f"    - Model: {self.model_name}")
        print(f"    - Temperature: {self.temperature}")
        print(f"    - Tools: {len(self.tools)} tools")

    def invoke(self, message: str, thread_id: str = "default_thread", **kwargs) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ ì‹¤í–‰

        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            thread_id: ëŒ€í™” ìŠ¤ë ˆë“œ ID
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„° (ê° ë§¤ë‹ˆì €ë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)

        Returns:
            ì—ì´ì „íŠ¸ ì‘ë‹µ
        """
        config = {"configurable": {"thread_id": thread_id}}

        # ë©”ì‹œì§€ ì „ì²˜ë¦¬ hook í˜¸ì¶œ (ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
        prepared_message = self._prepare_message(message, **kwargs)

        result = self.agent.invoke(
            {"messages": [{"role": "user", "content": prepared_message}]},
            config=config,
        )

        return result

    def stream(self, message: str, thread_id: str = "default_thread", **kwargs):
        """
        ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰

        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            thread_id: ëŒ€í™” ìŠ¤ë ˆë“œ ID
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°

        Yields:
            ì—ì´ì „íŠ¸ ì‘ë‹µ ì²­í¬
        """
        config = {"configurable": {"thread_id": thread_id}}

        # ë©”ì‹œì§€ ì „ì²˜ë¦¬ hook í˜¸ì¶œ (ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
        prepared_message = self._prepare_message(message, **kwargs)

        for chunk in self.agent.stream(
            {"messages": [{"role": "user", "content": prepared_message}]},
            config=config,
            stream_mode="values",
        ):
            yield chunk

    def get_state(self, config: dict):
        """
        ì—ì´ì „íŠ¸ì˜ í˜„ì¬ ìƒíƒœ ë°˜í™˜

        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (thread_id í¬í•¨)

        Returns:
            ì—ì´ì „íŠ¸ ìƒíƒœ
        """
        return self.agent.get_state(config)

    def invoke_command(self, command, config: dict):
        """
        Command ê°ì²´ë¥¼ ì‚¬ìš©í•œ ì—ì´ì „íŠ¸ ì‹¤í–‰ (HITL ìŠ¹ì¸ ì²˜ë¦¬ìš©)

        Args:
            command: langgraph Command ê°ì²´
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (thread_id í¬í•¨)

        Returns:
            ì—ì´ì „íŠ¸ ì‘ë‹µ
        """
        return self.agent.invoke(command, config)