# base_manager.py
"""
Base Manager Agent - ê³µí†µ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤

ëª¨ë“  ë§¤ë‹ˆì € ì—ì´ì „íŠ¸(ManagerS, ManagerM, ManagerI)ê°€ ìƒì†í•˜ëŠ” ë² ì´ìŠ¤ í´ë˜ìŠ¤ì…ë‹ˆë‹¤:
- ê³µí†µ ì´ˆê¸°í™” ë¡œì§
- ì—ì´ì „íŠ¸ ìƒì„± íŒ¨í„´
- invoke/stream/get_state ë©”ì„œë“œ
- í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê´€ë¦¬
- hook ë©”ì„œë“œë¥¼ í†µí•œ í™•ì¥ ì§€ì›

"""

from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any
from pathlib import Path
from langchain.agents import create_agent
from agents.context import TeamHContext
from agents.middleware import LangfuseToolLoggingMiddleware
from utils.llm_factory import create_llm

class AgentBase(ABC):
    """ëª¨ë“  ë§¤ë‹ˆì € ì—ì´ì „íŠ¸ì˜ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    # í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    PROMPTS_DIR = Path(__file__).parent / "prompts"

    # ê¸°ë³¸ Context Schema (ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
    CONTEXT_SCHEMA = TeamHContext

    @property
    @abstractmethod
    def prompt_filename(self) -> str:
        """
        í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª… (ìì‹ í´ë˜ìŠ¤ì—ì„œ ë°˜ë“œì‹œ êµ¬í˜„)

        Returns:
            í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª… (ì˜ˆ: "manager_s.yaml")
        """
        pass

    def __init__(
        self,
        model_name: str = "gpt-4o-mini",
        temperature: float = 0.7,
        additional_tools: Optional[List] = None,
        additional_middleware: Optional[List] = None,
        enable_langfuse_logging: bool = False,
        context_schema: Optional[type] = None,
        **kwargs,
    ):
        """
        ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”

        Args:
            model_name: ì‚¬ìš©í•  LLM ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: gpt-4o-mini)
            temperature: ëª¨ë¸ temperature ì„¤ì •
            additional_tools: í•¸ë“œì˜¤í”„ ë“± ì¶”ê°€ íˆ´ ë¦¬ìŠ¤íŠ¸
            additional_middleware: ì¶”ê°€ ë¯¸ë“¤ì›¨ì–´ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: HumanInTheLoopMiddleware)
            enable_langfuse_logging: Langfuse íˆ´ ë¡œê¹… í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            context_schema: Runtime context ìŠ¤í‚¤ë§ˆ (ê¸°ë³¸ê°’: TeamHContext)
            **kwargs: ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ íŒŒë¼ë¯¸í„°
        """
        manager_type = self.__class__.__name__
        print(f"[ğŸ¤–] Initializing {manager_type} Agent...")

        self.model_name = model_name
        self.temperature = temperature

        # ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ hook
        # ì´ ë©”ì„œë“œëŠ” _create_tools() í˜¸ì¶œ ì „ì— ì‹¤í–‰ë˜ì–´ì•¼ í•¨
        # (íˆ´ ìƒì„± ì‹œ ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ ì†ì„±ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
        self._pre_init_hook(**kwargs)

        # ê° ë§¤ë‹ˆì €ê°€ ìì‹ ì˜ íˆ´ì„ ìƒì„±
        self.tools = self._create_tools()
        if additional_tools:
            self.tools.extend(additional_tools)
            print(f"[â•] Added {len(additional_tools)} additional tools (handoff tools)")

        # LLM ëª¨ë¸ ìƒì„± (ì¤‘ì•™í™”ëœ factory ì‚¬ìš©)
        model = create_llm()

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        base_prompt = self._get_base_prompt()

        # í•¸ë“œì˜¤í”„ íˆ´ì´ ìˆìœ¼ë©´ í˜‘ì—… í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if additional_tools:
            handoff_prompt = self._get_handoff_prompt()
            system_prompt = base_prompt + handoff_prompt
        else:
            system_prompt = base_prompt

        # ê³µí†µ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ê°€
        system_prompt += self._get_closing_prompt()

        # ë¯¸ë“¤ì›¨ì–´ êµ¬ì„±
        # 1. ê¸°ë³¸ ë¯¸ë“¤ì›¨ì–´: Langfuse íˆ´ ë¡œê¹… (ì„ íƒì )
        middlewares = []
        if enable_langfuse_logging:
            try:
                langfuse_middleware = LangfuseToolLoggingMiddleware(verbose=True)
                middlewares.append(langfuse_middleware)
                print(f"[ğŸ“Š] Langfuse tool logging enabled")
            except Exception as e:
                print(f"[âš ï¸] Langfuse middleware initialization failed: {e}")

        # 2. ì¶”ê°€ ë¯¸ë“¤ì›¨ì–´ ë³‘í•©
        if additional_middleware:
            middlewares.extend(additional_middleware)
            print(f"[â•] Added {len(additional_middleware)} additional middleware(s)")

        # ì—ì´ì „íŠ¸ ìƒì„± (LangChain v1)
        # Note: checkpointerëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        # TeamHGraphê°€ ìƒìœ„ ë ˆë²¨ì—ì„œ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê³ ,
        # ê° ManagerëŠ” state["messages"]ë¥¼ í†µí•´ ëŒ€í™” ë§¥ë½ì„ ë°›ìŒ
        agent_kwargs = {
            "model": model,
            "tools": self.tools,
            "system_prompt": system_prompt,
            "context_schema": context_schema or self.CONTEXT_SCHEMA,
        }

        # ë¯¸ë“¤ì›¨ì–´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if middlewares:
            agent_kwargs["middleware"] = middlewares

        self.agent = create_agent(**agent_kwargs)

        # ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€
        self._print_initialization_summary()

    def _pre_init_hook(self, **kwargs):
        """
        ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ hook

        _create_tools() í˜¸ì¶œ ì „ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ íŠ¹ìˆ˜ ì†ì„±ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”.

        Args:
            **kwargs: ìì‹ í´ë˜ìŠ¤ì˜ íŠ¹ìˆ˜ íŒŒë¼ë¯¸í„°

        Example:
            class ManagerM(AgentBase):
                def _pre_init_hook(self, **kwargs):
                    self.memory = ManagerMMemory(
                        embedder_url=kwargs.get("embedder_url"),
                        ...
                    )
        """
        pass

    @abstractmethod
    def _create_tools(self) -> List:
        """
        ê° ë§¤ë‹ˆì €ê°€ ìì‹ ì˜ íˆ´ì„ ì •ì˜

        Returns:
            íˆ´ í•¨ìˆ˜ ë¦¬ìŠ¤íŠ¸
        """
        pass

    def _load_prompt_from_file(self, filename: str) -> str:
        """
        í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ (YAML í˜•ì‹)

        Args:
            filename: í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª… (prompts/ ë””ë ‰í† ë¦¬ ë‚´)

        Returns:
            í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´

        Raises:
            FileNotFoundError: í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ì„ ê²½ìš°
        """
        prompt_path = self.PROMPTS_DIR / filename

        if not prompt_path.exists():
            raise FileNotFoundError(
                f"Prompt file not found: {prompt_path}\n"
                f"Please create the prompt file at: {prompt_path}"
            )

        # YAML íŒŒì¼ ì½ê¸°
        try:
            import yaml
            with open(prompt_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)

            # 'content' í‚¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
            if isinstance(data, dict) and 'content' in data:
                return data['content'].strip()
            else:
                raise ValueError(f"YAML file must contain 'content' key: {prompt_path}")
        except Exception as e:
            raise ValueError(f"Failed to load YAML prompt from {prompt_path}: {e}")

    def _get_base_prompt(self) -> str:
        """
        ë² ì´ìŠ¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜

        ê¸°ë³¸ì ìœ¼ë¡œ prompts/ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        ìì‹ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ ì§ì ‘ ë¬¸ìì—´ ë°˜í™˜ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.

        Returns:
            ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        return self._load_prompt_from_file(self.prompt_filename)

    def _get_handoff_prompt(self) -> str:
        """
        í•¸ë“œì˜¤í”„ íˆ´ì´ ìˆì„ ë•Œ ì¶”ê°€ë˜ëŠ” í˜‘ì—… í”„ë¡¬í”„íŠ¸

        ê¸°ë³¸ì ìœ¼ë¡œ prompts/handoff_common.yamlì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.

        Returns:
            í•¸ë“œì˜¤í”„ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        return self._load_prompt_from_file("handoff_common.yaml")

    def _get_closing_prompt(self) -> str:
        """
        ëª¨ë“  í”„ë¡¬í”„íŠ¸ ë§ˆì§€ë§‰ì— ì¶”ê°€ë˜ëŠ” ê³µí†µ ë©”ì‹œì§€

        Returns:
            ë§ˆì§€ë§‰ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        return "\n\nBe helpful, accurate, and respond in Korean when appropriate."

    def _print_initialization_summary(self):
        """ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥"""
        manager_type = self.__class__.__name__
        print(f"[âœ…] {manager_type} Agent initialized successfully")
        print(f"    - Model: {self.model_name}")
        print(f"    - Temperature: {self.temperature}")
        print(f"    - Tools: {len(self.tools)} tools")

    def invoke(self, message: str, thread_id: str = "default_thread", **kwargs) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ ì‹¤í–‰

        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            thread_id: ëŒ€í™” ìŠ¤ë ˆë“œ ID
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„° (ê° ë§¤ë‹ˆì €ë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)

        Returns:
            ì—ì´ì „íŠ¸ ì‘ë‹µ
        """
        config = {"configurable": {"thread_id": thread_id}}

        result = self.agent.invoke(
            {"messages": [{"role": "user", "content": message}]},
            config=config,
        )

        return result

    def get_state(self, config: dict):
        """
        ì—ì´ì „íŠ¸ì˜ í˜„ì¬ ìƒíƒœ ë°˜í™˜

        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (thread_id í¬í•¨)

        Returns:
            ì—ì´ì „íŠ¸ ìƒíƒœ
        """
        return self.agent.get_state(config)

    def invoke_command(self, command, config: dict):
        """
        Command ê°ì²´ë¥¼ ì‚¬ìš©í•œ ì—ì´ì „íŠ¸ ì‹¤í–‰ (HITL ìŠ¹ì¸ ì²˜ë¦¬ìš©)

        Args:
            command: langgraph Command ê°ì²´
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (thread_id í¬í•¨)

        Returns:
            ì—ì´ì „íŠ¸ ì‘ë‹µ
        """
        return self.agent.invoke(command, config)