# vector_store_teamh.py
from functools import wraps
from langchain.embeddings.base import Embeddings
from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode
from qdrant_client import QdrantClient, models
from qdrant_client.http.models import Distance, SparseVectorParams, VectorParams, Filter, FieldCondition, MatchValue, MatchAny
from langchain_core.documents import Document
from collections import defaultdict
import traceback
import time
from typing import Optional, Dict, Any, List, Set
from database.qdrant.fastapi_embedder_adapter import FastAPIEmbedderAdapter
from database.qdrant.openai_embedder_adapter import OpenAIEmbedderAdapter
from database.qdrant.config import MemoryConfig

def timing_step(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        print(f"\n[â±ï¸] Starting '{func.__name__}'...")
        start_time = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start_time
        print(f"[âœ…] Finished '{func.__name__}' in {elapsed:.2f} seconds\n")
        return result
    return wrapper

def create_qdrant_filter(metadata_filter: Optional[Dict[str, Any]]) -> Optional[Filter]:
    """`None`, `"None"`, ë¹ˆ ë¦¬ìŠ¤íŠ¸ëŠ” ë¬´ì‹œí•˜ê³  ì¡°ê±´ì„ ë§Œë“ ë‹¤."""
    if not metadata_filter:
        return None

    conditions = []
    for field, value in metadata_filter.items():
        if value is None or \
            value == "None" or \
            (isinstance(value, list) and not value):
            continue

        key = f"metadata.{field}"
        if isinstance(value, list):
            conditions.append(FieldCondition(key=key, match=MatchAny(any=value)))
        else:
            conditions.append(FieldCondition(key=key, match=MatchValue(value=value)))

    return Filter(must=conditions) if conditions else None


class VectorStore:
    @timing_step
    def __init__(
        self,
        url="http://localhost:6333",
        api_key=None,
        collection_name=None,
        dense_size=None,
        recreate_collection=True,
        embedding_type=None,
        embedder_url=None,
        openai_api_key=None,
    ):
        """
        VectorStore ì´ˆê¸°í™”

        Args:
            url: Qdrant ì„œë²„ URL
            api_key: Qdrant API í‚¤
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            dense_size: ì„ë² ë”© ì°¨ì› (ê¸°ë³¸ê°’: embedding_typeì— ë”°ë¼ ìë™ ì„¤ì •)
            recreate_collection: ì»¬ë ‰ì…˜ ì¬ìƒì„± ì—¬ë¶€
            embedding_type: ì„ë² ë”© íƒ€ì… ("fastapi" ë˜ëŠ” "openai", ê¸°ë³¸ê°’: configì—ì„œ ë¡œë“œ)
            embedder_url: FastAPI ì„ë² ë”© ì„œë²„ URL (embedding_type="fastapi"ì¼ ë•Œ ì‚¬ìš©)
            openai_api_key: OpenAI API í‚¤ (embedding_type="openai"ì¼ ë•Œ ì‚¬ìš©)
        """
        self.url = url
        self.api_key = api_key
        self.collection_name = collection_name
        self.recreate_collection = recreate_collection

        # embedding_type ê²°ì • (íŒŒë¼ë¯¸í„° > config > ê¸°ë³¸ê°’)
        embedding_type = embedding_type or MemoryConfig.EMBEDDING_TYPE

        # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client_args = {'url': url, 'timeout': 60}
        if api_key:
            client_args['api_key'] = api_key
        self.client = QdrantClient(**client_args)

        self.sparse_embedder = self._create_sparse_embedder()

        # ì„ë² ë”© íƒ€ì…ì— ë”°ë¼ embedder ì´ˆê¸°í™”
        if embedding_type == "fastapi":
            embedder_url = embedder_url or MemoryConfig.EMBEDDER_URL
            dense_size = dense_size or MemoryConfig.FASTAPI_EMBEDDING_DIMS

            print(f"[ğŸ”—] Initializing FastAPI Embedder: {embedder_url}")
            self.embedder = FastAPIEmbedderAdapter(
                base_url=embedder_url,
                retry_attempts=3,
                retry_delay=2,
                timeout=60
            )
            self.dense_size = dense_size

        elif embedding_type == "openai":
            openai_api_key = openai_api_key or MemoryConfig.OPENAI_API_KEY
            dense_size = dense_size or MemoryConfig.OPENAI_EMBEDDING_DIMS

            print(f"[ğŸ”—] Initializing OpenAI Embedder: text-embedding-3-large")
            self.embedder = OpenAIEmbedderAdapter(
                api_key=openai_api_key,
                dimensions=dense_size,
            )
            self.dense_size = dense_size

        else:
            raise ValueError(f"Invalid embedding_type: {embedding_type}. Must be 'fastapi' or 'openai'.")

        self.embedding_type = embedding_type

        self._ensure_collection_exists()
        self.vector_store = self._create_vector_store()

    @staticmethod
    def _filter_internal_metadata(metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„°ì—ì„œ '_'ë¡œ ì‹œì‘í•˜ëŠ” ë‚´ë¶€ í‚¤ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."""
        if not metadata:
            return {}
        return {k: v for k, v in metadata.items() if not k.startswith('_')}

    @timing_step
    def delete_collection(self):
        """ì»¬ë ‰ì…˜ì„ ì‚­ì œí•˜ëŠ” ë©”ì„œë“œ"""
        try:
            print(f"Attempting to delete collection '{self.collection_name}'...")
            self.client.delete_collection(collection_name=self.collection_name)
            print(f"Collection '{self.collection_name}' deleted successfully")
            return True
        except Exception as e:
            print(f"Error deleting collection '{self.collection_name}': {e}")
            return False

    @timing_step
    def _ensure_collection_exists(self):
        """ì½œë ‰ì…˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±"""
        try:
            collections_response = self.client.get_collections()
            collection_names = [c.name for c in collections_response.collections]
            print(f"Existing collections: {collection_names}")
            collection_exists = self.collection_name in collection_names

            if self.recreate_collection and collection_exists:
                print(f"Recreate option is enabled. Deleting existing collection '{self.collection_name}'...")
                deleted = self.delete_collection()
                if deleted:
                    collection_exists = False
                else:
                    print(f"[âš ï¸] Failed to delete collection '{self.collection_name}'.")

            if not collection_exists:
                print(f"Collection '{self.collection_name}' does not exist or was deleted. Creating...")
                self.create_collection()
            else:
                print(f"Collection '{self.collection_name}' already exists and recreate=False.")

        except Exception as e:
            print(f"[âŒ] Error ensuring collection exists: {e}")
            raise

    @timing_step
    def create_collection(self):
        """Create a collection with both dense and sparse vectors"""
        try:
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config={"dense": VectorParams(size=self.dense_size, distance=Distance.COSINE)},
                sparse_vectors_config={"sparse": SparseVectorParams(index=models.SparseIndexParams(on_disk=False))},
            )
            print(f"Collection '{self.collection_name}' created successfully")
        except Exception as e:
            print(f"[âŒ] Error creating collection '{self.collection_name}': {e}")
            pass

    @timing_step
    def _create_sparse_embedder(self):
        return FastEmbedSparse(model_name="Qdrant/bm25")

    @timing_step
    def _create_vector_store(self):
        """Langchain QdrantVectorStore ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.embedder:
             raise RuntimeError("[âŒ] Dense embedder is not available.")
        if not self.sparse_embedder:
             print("[âš ï¸] Sparse embedder is not available. Hybrid search might not work as expected.")

        try:
            _ = self.embedder.embed_query("connection test")
            print("[âœ…] Embedder connection verified before creating VectorStore.")
        except Exception as e:
            print(f"[âŒ] Failed to verify embedder connection: {e}")

        return QdrantVectorStore(
            client=self.client,
            collection_name=self.collection_name,
            embedding=self.embedder,
            sparse_embedding=self.sparse_embedder,
            retrieval_mode=RetrievalMode.HYBRID,
            vector_name="dense",
            sparse_vector_name="sparse",
        )

    @timing_step
    def add_documents(self, documents, batch_size=64):
        """Langchain Document ë¦¬ìŠ¤íŠ¸ë¥¼ Qdrantì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        total = len(documents)
        if not total:
            print("[âš ï¸] No documents provided to add.")
            return

        print(f"Starting to add {total} documents using Langchain's add_documents...")
        try:
            ids_returned = self.vector_store.add_documents(documents=documents)
            print(f"[âœ…] Successfully added {total} documents. Returned IDs count: {len(ids_returned)}")

        except Exception as e:
            print(f"[âŒ] Error adding documents via Langchain: {e}")
            print(traceback.format_exc())

    @timing_step
    def search(self, query: str, k: int = 4, metadata_filter: dict = None):
        """Langchain VectorStoreë¥¼ ì´ìš©í•œ ê¸°ë³¸ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì ìš©)"""
        qdrant_filter = create_qdrant_filter(metadata_filter)
        if qdrant_filter:
            print(f"[ğŸ”] ìƒì„±ëœ í•„í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤: {metadata_filter}")

        try:
             if not self.vector_store: raise RuntimeError("[âŒ] Vector store is not initialized.")
             print(f"[ğŸ”] Performing similarity search for query: '{query[:50]}...' with k={k}")
             results = self.vector_store.similarity_search(query=query, k=k, filter=qdrant_filter)
             for doc in results:
                 doc.metadata = self._filter_internal_metadata(doc.metadata)
             print(f"[âœ…] Found {len(results)} results.")
             return results
        except Exception as e:
             print(f"[âŒ] Error during similarity search: {e}")
             return []

    @timing_step
    def search_with_score(self, query: str, k: int = 4, metadata_filter: dict = None):
        """Langchain VectorStoreë¥¼ ì´ìš©í•œ ì ìˆ˜ í¬í•¨ ê²€ìƒ‰"""
        qdrant_filter = create_qdrant_filter(metadata_filter)
        if qdrant_filter:
             print(f"[ğŸ”] ìƒì„±ëœ í•„í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤: {metadata_filter}")

        try:
             if not self.vector_store: raise RuntimeError("[âŒ] Vector store is not initialized.")
             print(f"[ğŸ”] Performing similarity search with score for query: '{query[:50]}...' with k={k}")
             results = self.vector_store.similarity_search_with_score(query=query, k=k, filter=qdrant_filter)
             for doc, score in results:
                 doc.metadata = self._filter_internal_metadata(doc.metadata)
             print(f"[âœ…] Found {len(results)} results with scores.")
             return results
        except Exception as e:
             print(f"[âŒ] Error during similarity search with score: {e}")
             return []
